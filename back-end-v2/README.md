# Rubi Studio Backend API - Version 2.0

Backend FastAPI am√©lior√© avec corrections critiques et fonctionnalit√©s avanc√©es.

## üöÄ Nouvelles Fonctionnalit√©s (v2.0)

### ‚úÖ Corrections Critiques

1. **Ex√©cution R√©elle des Prompts avec LLM**
   - Int√©gration compl√®te OpenAI, Gemini, Claude
   - Abstraction unifi√©e des providers LLM
   - Calcul automatique des co√ªts

2. **Validation des Variables**
   - Validation robuste avec jsonschema
   - Messages d'erreur d√©taill√©s
   - Enrichissement avec valeurs par d√©faut

3. **Authentification JWT**
   - Endpoints register/login
   - Protection des routes sensibles
   - Gestion des tokens

4. **Historique d'Ex√©cution Complet**
   - Enregistrement de toutes les ex√©cutions
   - Endpoints de consultation
   - Filtres par prompt, statut, date

5. **M√©triques Prometheus**
   - M√©triques d√©taill√©es (ex√©cutions, tokens, co√ªts)
   - Endpoint /metrics
   - Pr√™t pour Grafana

### üéØ Fonctionnalit√©s Principales

- **Gestion des Sp√©cialit√©s** : CRUD complet pour specialties, sub-specialties, expert prompts
- **Support Multi-LLM** : OpenAI (GPT-4, GPT-3.5), Gemini (Pro, Flash), Claude (Opus, Sonnet, Haiku)
- **Validation Avanc√©e** : Validation des variables contre sch√©mas JSON
- **S√©curit√©** : Authentification JWT, hachage bcrypt
- **Monitoring** : M√©triques Prometheus, logging structur√©
- **Base de Donn√©es** : Support PostgreSQL et SQLite

## üìã Pr√©requis

- Python 3.11+
- PostgreSQL 15+ (recommand√©) ou SQLite (d√©veloppement)
- Redis 7+ (pour Celery, optionnel)
- Cl√©s API pour les LLM :
  - `OPENAI_API_KEY`
  - `GEMINI_API_KEY`
  - `ANTHROPIC_API_KEY`

## üõ†Ô∏è Installation

### 1. Cloner le repository

```bash
git clone https://github.com/pivori-app/rubi-studio.git
cd rubi-studio/back-end-v2
```

### 2. Cr√©er un environnement virtuel

```bash
python3.11 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 4. Configurer les variables d'environnement

Cr√©er un fichier `.env` :

```env
# Base de donn√©es
DATABASE_URL=postgresql://user:password@localhost:5432/rubi_studio
# ou pour SQLite (d√©veloppement)
# DATABASE_URL=sqlite:///./rubi_studio.db

# JWT
JWT_SECRET=your-secret-key-change-in-production

# LLM API Keys
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=...
ANTHROPIC_API_KEY=sk-ant-...

# Redis (optionnel, pour Celery)
REDIS_URL=redis://localhost:6379/0
```

### 5. Initialiser la base de donn√©es

```bash
# Avec Alembic (recommand√©)
alembic upgrade head

# Ou laisser SQLAlchemy cr√©er les tables automatiquement au d√©marrage
```

## üöÄ D√©marrage

### Mode D√©veloppement

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Mode Production

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Avec Gunicorn (Production)

```bash
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## üìö Documentation API

Une fois le serveur d√©marr√©, acc√©dez √† :

- **Swagger UI** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc
- **M√©triques Prometheus** : http://localhost:8000/metrics
- **Health Check** : http://localhost:8000/health

## üîê Authentification

### 1. Cr√©er un compte

```bash
curl -X POST "http://localhost:8000/api/v1/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "username": "user",
    "password": "securepassword"
  }'
```

### 2. Se connecter

```bash
curl -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securepassword"
  }'
```

R√©ponse :
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

### 3. Utiliser le token

```bash
curl -X GET "http://localhost:8000/api/v1/auth/me" \
  -H "Authorization: Bearer <votre-token>"
```

## üéØ Exemples d'Utilisation

### Cr√©er une Sp√©cialit√©

```bash
curl -X POST "http://localhost:8000/api/v1/specialties" \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "D√©veloppement Web",
    "description": "Sp√©cialit√© en d√©veloppement web full-stack",
    "icon_url": "https://example.com/icon.png"
  }'
```

### Cr√©er un Prompt Expert

```bash
curl -X POST "http://localhost:8000/api/v1/expert-prompts" \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "sub_specialty_id": 1,
    "title": "Cr√©er une API REST",
    "template": "Cr√©er une API REST avec {framework} pour {use_case}",
    "variables_schema": {
      "type": "object",
      "properties": {
        "framework": {
          "type": "string",
          "enum": ["FastAPI", "Express", "Django"],
          "description": "Framework web √† utiliser"
        },
        "use_case": {
          "type": "string",
          "description": "Cas d'\''utilisation de l'\''API"
        }
      },
      "required": ["framework", "use_case"]
    },
    "expected_output": "Code source complet de l'\''API"
  }'
```

### Ex√©cuter un Prompt

```bash
curl -X POST "http://localhost:8000/api/v1/execute-prompt/1" \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "variables": {
      "framework": "FastAPI",
      "use_case": "gestion de t√¢ches"
    },
    "llm_provider": "openai",
    "llm_model": "gpt-4",
    "temperature": 0.7
  }'
```

R√©ponse :
```json
{
  "execution_id": 123,
  "prompt_id": 1,
  "output": "Voici le code complet de l'API...",
  "llm_provider": "openai",
  "llm_model": "gpt-4",
  "tokens_used": 1500,
  "cost": 0.045,
  "execution_time": 3.2,
  "status": "success"
}
```

### Consulter l'Historique

```bash
curl -X GET "http://localhost:8000/api/v1/executions/history?limit=10" \
  -H "Authorization: Bearer <token>"
```

## üß™ Tests

```bash
# Installer les d√©pendances de test
pip install pytest pytest-asyncio pytest-cov httpx

# Lancer les tests
pytest

# Avec couverture
pytest --cov=app --cov-report=html
```

## üìä Monitoring

### M√©triques Prometheus

Le endpoint `/metrics` expose les m√©triques suivantes :

- `prompt_executions_total` : Nombre total d'ex√©cutions
- `prompt_execution_duration_seconds` : Dur√©e des ex√©cutions
- `llm_tokens_used_total` : Tokens utilis√©s par LLM
- `llm_cost_total_usd` : Co√ªt total en USD
- `active_executions` : Nombre d'ex√©cutions actives

### Configuration Grafana

Importer le dashboard Grafana depuis `grafana/dashboard.json` (√† cr√©er).

## üîß Configuration Avanc√©e

### PostgreSQL

```bash
# Cr√©er la base de donn√©es
createdb rubi_studio

# Configurer l'URL
export DATABASE_URL=postgresql://user:password@localhost:5432/rubi_studio
```

### Redis (pour Celery)

```bash
# D√©marrer Redis
redis-server

# D√©marrer Celery worker
celery -A app.celery_app worker --loglevel=info
```

## üìù Structure du Projet

```
back-end-v2/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Application FastAPI principale
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Mod√®les SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py           # Sch√©mas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Configuration base de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ llm_providers.py     # Abstraction des LLM
‚îÇ   ‚îî‚îÄ‚îÄ validators.py        # Validation des variables
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îî‚îÄ‚îÄ README.md               # Ce fichier
```

## üêõ D√©pannage

### Erreur "OPENAI_API_KEY not set"

Assurez-vous d'avoir configur√© les variables d'environnement :

```bash
export OPENAI_API_KEY=sk-...
export GEMINI_API_KEY=...
export ANTHROPIC_API_KEY=sk-ant-...
```

### Erreur de connexion PostgreSQL

V√©rifiez que PostgreSQL est d√©marr√© et que l'URL est correcte :

```bash
psql -U user -d rubi_studio -h localhost
```

### Erreur "Could not validate credentials"

Le token JWT a expir√©. Reconnectez-vous pour obtenir un nouveau token.

## üìÑ Licence

Propri√©taire - Rubi Studio ¬© 2025

## üë• Contributeurs

- √âquipe Rubi Studio

## üìû Support

Pour toute question ou probl√®me, ouvrez une issue sur GitHub.

